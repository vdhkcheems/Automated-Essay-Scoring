{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antrskarya/VScode/AES/imp.py:191: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  x = re.sub(\"@\\w+\", '', x)  # Remove mentions\n",
      "/home/antrskarya/VScode/AES/imp.py:192: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  x = re.sub(\"'\\d+\", '', x)  # Remove contractions\n",
      "/home/antrskarya/VScode/AES/imp.py:193: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  x = re.sub(\"\\d+\", '', x)  # Remove digits\n",
      "/home/antrskarya/VScode/AES/imp.py:194: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  x = re.sub(\"http\\w+\", '', x)  # Remove URLs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import textstat\n",
    "\n",
    "from imp import *\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import torch\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import pickle\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took both the datasets then scaled their scores from 0 to 10 and combined both of these datasets with 3 columns in the combined dataset being the \"essay_id\", \"full_text\" and \"score\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30278</th>\n",
       "      <td>21626</td>\n",
       "      <td>In most stories mothers and daughters are eith...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30279</th>\n",
       "      <td>21628</td>\n",
       "      <td>I never understood the meaning laughter is the...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30280</th>\n",
       "      <td>21629</td>\n",
       "      <td>When you laugh, is out of habit, or is cause? ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30281</th>\n",
       "      <td>21630</td>\n",
       "      <td>Trippin' on fences I am years young, and in th...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30282</th>\n",
       "      <td>21633</td>\n",
       "      <td>Many people believe that laughter can improve ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30283 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  score\n",
       "0      000d118  Many people have car where they live. The thin...      5\n",
       "1      000fe60  I am a scientist at NASA that is discussing th...      5\n",
       "2      001ab80  People always wish they had the same technolog...      7\n",
       "3      001bdc0  We all heard about Venus, the planet without a...      7\n",
       "4      002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      5\n",
       "...        ...                                                ...    ...\n",
       "30278    21626  In most stories mothers and daughters are eith...      6\n",
       "30279    21628  I never understood the meaning laughter is the...      5\n",
       "30280    21629  When you laugh, is out of habit, or is cause? ...      7\n",
       "30281    21630  Trippin' on fences I am years young, and in th...      7\n",
       "30282    21633  Many people believe that laughter can improve ...      7\n",
       "\n",
       "[30283 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"Datasets/train.csv\")\n",
    "data2 = pd.read_csv(\"Datasets/old_compdata.csv\")\n",
    "data2 = data2[[\"essay_id\", \"essay\",\"final_score\"]].copy()\n",
    "\n",
    "data2.rename(columns={\"essay\":\"full_text\", \"final_score\":\"score\"}, inplace=True)\n",
    "data1[\"score\"] = data1[\"score\"].apply(score_normalise)\n",
    "combined_data = pd.concat([data1, data2], axis=0)\n",
    "combined_data = combined_data.reset_index(drop=True)\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  function \"dataPreprocessing\" converts the text into lowercase, removes all the punctions, html tags, urls and much more, it also expands contractions like converting can't to cannot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply text preprocessing\n",
    "combined_data['cleaned_essay_text'] = combined_data['full_text'].apply(dataPreprocessing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have extracted some self implemented features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>cleaned_essay_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>spell_error</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>para_count</th>\n",
       "      <th>avg_para_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>5</td>\n",
       "      <td>many people have car where they live the thing...</td>\n",
       "      <td>545</td>\n",
       "      <td>4.007339</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>38.307692</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>5</td>\n",
       "      <td>i am a scientist at nasa that is discussing th...</td>\n",
       "      <td>371</td>\n",
       "      <td>3.617251</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>15.809524</td>\n",
       "      <td>5</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>7</td>\n",
       "      <td>people always wish they had the same technolog...</td>\n",
       "      <td>605</td>\n",
       "      <td>4.178512</td>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "      <td>22.916667</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>7</td>\n",
       "      <td>we all heard about venus the planet without al...</td>\n",
       "      <td>511</td>\n",
       "      <td>4.405088</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>21.571429</td>\n",
       "      <td>5</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>5</td>\n",
       "      <td>dear state senator this is a letter to argue i...</td>\n",
       "      <td>418</td>\n",
       "      <td>4.354067</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>6</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30278</th>\n",
       "      <td>21626</td>\n",
       "      <td>In most stories mothers and daughters are eith...</td>\n",
       "      <td>6</td>\n",
       "      <td>in most stories mothers and daughters are eith...</td>\n",
       "      <td>894</td>\n",
       "      <td>3.627517</td>\n",
       "      <td>74</td>\n",
       "      <td>26</td>\n",
       "      <td>30.692308</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30279</th>\n",
       "      <td>21628</td>\n",
       "      <td>I never understood the meaning laughter is the...</td>\n",
       "      <td>5</td>\n",
       "      <td>i never understood the meaning laughter is the...</td>\n",
       "      <td>596</td>\n",
       "      <td>3.466443</td>\n",
       "      <td>62</td>\n",
       "      <td>39</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30280</th>\n",
       "      <td>21629</td>\n",
       "      <td>When you laugh, is out of habit, or is cause? ...</td>\n",
       "      <td>7</td>\n",
       "      <td>when you laugh is out of habit or is cause wha...</td>\n",
       "      <td>883</td>\n",
       "      <td>3.853907</td>\n",
       "      <td>100</td>\n",
       "      <td>52</td>\n",
       "      <td>17.568182</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30281</th>\n",
       "      <td>21630</td>\n",
       "      <td>Trippin' on fences I am years young, and in th...</td>\n",
       "      <td>7</td>\n",
       "      <td>trippin on fences i am years young and in thos...</td>\n",
       "      <td>641</td>\n",
       "      <td>3.578783</td>\n",
       "      <td>73</td>\n",
       "      <td>39</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30282</th>\n",
       "      <td>21633</td>\n",
       "      <td>Many people believe that laughter can improve ...</td>\n",
       "      <td>7</td>\n",
       "      <td>many people believe that laughter can improve ...</td>\n",
       "      <td>512</td>\n",
       "      <td>3.808594</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>16.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30283 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  score  \\\n",
       "0      000d118  Many people have car where they live. The thin...      5   \n",
       "1      000fe60  I am a scientist at NASA that is discussing th...      5   \n",
       "2      001ab80  People always wish they had the same technolog...      7   \n",
       "3      001bdc0  We all heard about Venus, the planet without a...      7   \n",
       "4      002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      5   \n",
       "...        ...                                                ...    ...   \n",
       "30278    21626  In most stories mothers and daughters are eith...      6   \n",
       "30279    21628  I never understood the meaning laughter is the...      5   \n",
       "30280    21629  When you laugh, is out of habit, or is cause? ...      7   \n",
       "30281    21630  Trippin' on fences I am years young, and in th...      7   \n",
       "30282    21633  Many people believe that laughter can improve ...      7   \n",
       "\n",
       "                                      cleaned_essay_text  word_count  \\\n",
       "0      many people have car where they live the thing...         545   \n",
       "1      i am a scientist at nasa that is discussing th...         371   \n",
       "2      people always wish they had the same technolog...         605   \n",
       "3      we all heard about venus the planet without al...         511   \n",
       "4      dear state senator this is a letter to argue i...         418   \n",
       "...                                                  ...         ...   \n",
       "30278  in most stories mothers and daughters are eith...         894   \n",
       "30279  i never understood the meaning laughter is the...         596   \n",
       "30280  when you laugh is out of habit or is cause wha...         883   \n",
       "30281  trippin on fences i am years young and in thos...         641   \n",
       "30282  many people believe that laughter can improve ...         512   \n",
       "\n",
       "       avg_word_length  spell_error  sent_count  avg_sent_length  para_count  \\\n",
       "0             4.007339           54          13        38.307692           1   \n",
       "1             3.617251           34          23        15.809524           5   \n",
       "2             4.178512           43          24        22.916667           4   \n",
       "3             4.405088           48          24        21.571429           5   \n",
       "4             4.354067           41          15        23.437500           6   \n",
       "...                ...          ...         ...              ...         ...   \n",
       "30278         3.627517           74          26        30.692308           1   \n",
       "30279         3.466443           62          39        13.666667           1   \n",
       "30280         3.853907          100          52        17.568182           1   \n",
       "30281         3.578783           73          39        15.083333           1   \n",
       "30282         3.808594           47          28        16.285714           1   \n",
       "\n",
       "       avg_para_length  \n",
       "0                 13.0  \n",
       "1                  4.6  \n",
       "2                  6.0  \n",
       "3                  4.8  \n",
       "4                  2.5  \n",
       "...                ...  \n",
       "30278             26.0  \n",
       "30279             39.0  \n",
       "30280             52.0  \n",
       "30281             39.0  \n",
       "30282             28.0  \n",
       "\n",
       "[30283 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Apply feature extraction\n",
    "combined_data['word_count'], combined_data['avg_word_length'], combined_data['spell_error'], combined_data['sent_count'], combined_data['avg_sent_length'], combined_data['para_count'], combined_data['avg_para_length'] = zip(*combined_data['full_text'].apply(extract_features))\n",
    "\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have extracted features using textstat library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>cleaned_essay_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>spell_error</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>para_count</th>\n",
       "      <th>avg_para_length</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>difficult_words</th>\n",
       "      <th>text_standard</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>syllable_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>many people have car where they live the thing...</td>\n",
       "      <td>545</td>\n",
       "      <td>4.007339</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>38.307692</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-402.53</td>\n",
       "      <td>244.8</td>\n",
       "      <td>62</td>\n",
       "      <td>192.0</td>\n",
       "      <td>31.05</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>i am a scientist at nasa that is discussing th...</td>\n",
       "      <td>371</td>\n",
       "      <td>3.617251</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>15.809524</td>\n",
       "      <td>5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>-234.72</td>\n",
       "      <td>164.3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.04</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>people always wish they had the same technolog...</td>\n",
       "      <td>605</td>\n",
       "      <td>4.178512</td>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "      <td>22.916667</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-469.86</td>\n",
       "      <td>274.6</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.14</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>we all heard about venus the planet without al...</td>\n",
       "      <td>511</td>\n",
       "      <td>4.405088</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>21.571429</td>\n",
       "      <td>5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-369.72</td>\n",
       "      <td>223.1</td>\n",
       "      <td>80</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.91</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>dear state senator this is a letter to argue i...</td>\n",
       "      <td>418</td>\n",
       "      <td>4.354067</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-297.65</td>\n",
       "      <td>186.9</td>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.93</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30278</th>\n",
       "      <td>6</td>\n",
       "      <td>in most stories mothers and daughters are eith...</td>\n",
       "      <td>894</td>\n",
       "      <td>3.627517</td>\n",
       "      <td>74</td>\n",
       "      <td>26</td>\n",
       "      <td>30.692308</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-705.68</td>\n",
       "      <td>396.5</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.91</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30279</th>\n",
       "      <td>5</td>\n",
       "      <td>i never understood the meaning laughter is the...</td>\n",
       "      <td>596</td>\n",
       "      <td>3.466443</td>\n",
       "      <td>62</td>\n",
       "      <td>39</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-419.45</td>\n",
       "      <td>255.1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30280</th>\n",
       "      <td>7</td>\n",
       "      <td>when you laugh is out of habit or is cause wha...</td>\n",
       "      <td>883</td>\n",
       "      <td>3.853907</td>\n",
       "      <td>100</td>\n",
       "      <td>52</td>\n",
       "      <td>17.568182</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-676.58</td>\n",
       "      <td>379.6</td>\n",
       "      <td>84</td>\n",
       "      <td>297.0</td>\n",
       "      <td>47.58</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30281</th>\n",
       "      <td>7</td>\n",
       "      <td>trippin on fences i am years young and in thos...</td>\n",
       "      <td>641</td>\n",
       "      <td>3.578783</td>\n",
       "      <td>73</td>\n",
       "      <td>39</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-452.94</td>\n",
       "      <td>272.3</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.16</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30282</th>\n",
       "      <td>7</td>\n",
       "      <td>many people believe that laughter can improve ...</td>\n",
       "      <td>512</td>\n",
       "      <td>3.808594</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>16.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-369.04</td>\n",
       "      <td>227.6</td>\n",
       "      <td>47</td>\n",
       "      <td>179.0</td>\n",
       "      <td>27.88</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30283 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score                                 cleaned_essay_text  word_count  \\\n",
       "0          5  many people have car where they live the thing...         545   \n",
       "1          5  i am a scientist at nasa that is discussing th...         371   \n",
       "2          7  people always wish they had the same technolog...         605   \n",
       "3          7  we all heard about venus the planet without al...         511   \n",
       "4          5  dear state senator this is a letter to argue i...         418   \n",
       "...      ...                                                ...         ...   \n",
       "30278      6  in most stories mothers and daughters are eith...         894   \n",
       "30279      5  i never understood the meaning laughter is the...         596   \n",
       "30280      7  when you laugh is out of habit or is cause wha...         883   \n",
       "30281      7  trippin on fences i am years young and in thos...         641   \n",
       "30282      7  many people believe that laughter can improve ...         512   \n",
       "\n",
       "       avg_word_length  spell_error  sent_count  avg_sent_length  para_count  \\\n",
       "0             4.007339           54          13        38.307692           1   \n",
       "1             3.617251           34          23        15.809524           5   \n",
       "2             4.178512           43          24        22.916667           4   \n",
       "3             4.405088           48          24        21.571429           5   \n",
       "4             4.354067           41          15        23.437500           6   \n",
       "...                ...          ...         ...              ...         ...   \n",
       "30278         3.627517           74          26        30.692308           1   \n",
       "30279         3.466443           62          39        13.666667           1   \n",
       "30280         3.853907          100          52        17.568182           1   \n",
       "30281         3.578783           73          39        15.083333           1   \n",
       "30282         3.808594           47          28        16.285714           1   \n",
       "\n",
       "       avg_para_length  flesch_reading_ease  automated_readability_index  \\\n",
       "0                 13.0              -402.53                        244.8   \n",
       "1                  4.6              -234.72                        164.3   \n",
       "2                  6.0              -469.86                        274.6   \n",
       "3                  4.8              -369.72                        223.1   \n",
       "4                  2.5              -297.65                        186.9   \n",
       "...                ...                  ...                          ...   \n",
       "30278             26.0              -705.68                        396.5   \n",
       "30279             39.0              -419.45                        255.1   \n",
       "30280             52.0              -676.58                        379.6   \n",
       "30281             39.0              -452.94                        272.3   \n",
       "30282             28.0              -369.04                        227.6   \n",
       "\n",
       "       difficult_words  text_standard  reading_time  syllable_count  \n",
       "0                   62          192.0         31.05             627  \n",
       "1                   24            0.0         19.04             401  \n",
       "2                   66            0.0         36.14             767  \n",
       "3                   80           13.0         31.91             681  \n",
       "4                   58            0.0         25.93             560  \n",
       "...                ...            ...           ...             ...  \n",
       "30278               48            0.0         45.91             986  \n",
       "30279               27            0.0         29.00             607  \n",
       "30280               84          297.0         47.58            1001  \n",
       "30281               47            0.0         32.16             686  \n",
       "30282               47          179.0         27.88             613  \n",
       "\n",
       "[30283 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['textstat_features'] = combined_data['cleaned_essay_text'].apply(textstat_features)\n",
    "train_textstat = pd.DataFrame(combined_data['textstat_features'].tolist())\n",
    "\n",
    "# Ensure the indices are unique\n",
    "combined_data = combined_data.reset_index(drop=True)\n",
    "train_textstat = train_textstat.reset_index(drop=True)\n",
    "\n",
    "#making final dataset\n",
    "final_data = pd.concat([combined_data, train_textstat], axis=1)\n",
    "final_data = final_data.drop(columns=[\"textstat_features\", \"full_text\",\"essay_id\"])\n",
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(\"Datasets/final_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>cleaned_essay_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>spell_error</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>para_count</th>\n",
       "      <th>avg_para_length</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>difficult_words</th>\n",
       "      <th>text_standard</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>syllable_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>many people have car where they live the thing...</td>\n",
       "      <td>545</td>\n",
       "      <td>4.007339</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>38.307692</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-402.53</td>\n",
       "      <td>244.8</td>\n",
       "      <td>62</td>\n",
       "      <td>192.0</td>\n",
       "      <td>31.05</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>i am a scientist at nasa that is discussing th...</td>\n",
       "      <td>371</td>\n",
       "      <td>3.617251</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>15.809524</td>\n",
       "      <td>5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>-234.72</td>\n",
       "      <td>164.3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.04</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>people always wish they had the same technolog...</td>\n",
       "      <td>605</td>\n",
       "      <td>4.178512</td>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "      <td>22.916667</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-469.86</td>\n",
       "      <td>274.6</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.14</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>we all heard about venus the planet without al...</td>\n",
       "      <td>511</td>\n",
       "      <td>4.405088</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>21.571429</td>\n",
       "      <td>5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-369.72</td>\n",
       "      <td>223.1</td>\n",
       "      <td>80</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.91</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>dear state senator this is a letter to argue i...</td>\n",
       "      <td>418</td>\n",
       "      <td>4.354067</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-297.65</td>\n",
       "      <td>186.9</td>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.93</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30278</th>\n",
       "      <td>6</td>\n",
       "      <td>in most stories mothers and daughters are eith...</td>\n",
       "      <td>894</td>\n",
       "      <td>3.627517</td>\n",
       "      <td>74</td>\n",
       "      <td>26</td>\n",
       "      <td>30.692308</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-705.68</td>\n",
       "      <td>396.5</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.91</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30279</th>\n",
       "      <td>5</td>\n",
       "      <td>i never understood the meaning laughter is the...</td>\n",
       "      <td>596</td>\n",
       "      <td>3.466443</td>\n",
       "      <td>62</td>\n",
       "      <td>39</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-419.45</td>\n",
       "      <td>255.1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30280</th>\n",
       "      <td>7</td>\n",
       "      <td>when you laugh is out of habit or is cause wha...</td>\n",
       "      <td>883</td>\n",
       "      <td>3.853907</td>\n",
       "      <td>100</td>\n",
       "      <td>52</td>\n",
       "      <td>17.568182</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-676.58</td>\n",
       "      <td>379.6</td>\n",
       "      <td>84</td>\n",
       "      <td>297.0</td>\n",
       "      <td>47.58</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30281</th>\n",
       "      <td>7</td>\n",
       "      <td>trippin on fences i am years young and in thos...</td>\n",
       "      <td>641</td>\n",
       "      <td>3.578783</td>\n",
       "      <td>73</td>\n",
       "      <td>39</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-452.94</td>\n",
       "      <td>272.3</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.16</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30282</th>\n",
       "      <td>7</td>\n",
       "      <td>many people believe that laughter can improve ...</td>\n",
       "      <td>512</td>\n",
       "      <td>3.808594</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>16.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-369.04</td>\n",
       "      <td>227.6</td>\n",
       "      <td>47</td>\n",
       "      <td>179.0</td>\n",
       "      <td>27.88</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30283 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score                                 cleaned_essay_text  word_count  \\\n",
       "0          5  many people have car where they live the thing...         545   \n",
       "1          5  i am a scientist at nasa that is discussing th...         371   \n",
       "2          7  people always wish they had the same technolog...         605   \n",
       "3          7  we all heard about venus the planet without al...         511   \n",
       "4          5  dear state senator this is a letter to argue i...         418   \n",
       "...      ...                                                ...         ...   \n",
       "30278      6  in most stories mothers and daughters are eith...         894   \n",
       "30279      5  i never understood the meaning laughter is the...         596   \n",
       "30280      7  when you laugh is out of habit or is cause wha...         883   \n",
       "30281      7  trippin on fences i am years young and in thos...         641   \n",
       "30282      7  many people believe that laughter can improve ...         512   \n",
       "\n",
       "       avg_word_length  spell_error  sent_count  avg_sent_length  para_count  \\\n",
       "0             4.007339           54          13        38.307692           1   \n",
       "1             3.617251           34          23        15.809524           5   \n",
       "2             4.178512           43          24        22.916667           4   \n",
       "3             4.405088           48          24        21.571429           5   \n",
       "4             4.354067           41          15        23.437500           6   \n",
       "...                ...          ...         ...              ...         ...   \n",
       "30278         3.627517           74          26        30.692308           1   \n",
       "30279         3.466443           62          39        13.666667           1   \n",
       "30280         3.853907          100          52        17.568182           1   \n",
       "30281         3.578783           73          39        15.083333           1   \n",
       "30282         3.808594           47          28        16.285714           1   \n",
       "\n",
       "       avg_para_length  flesch_reading_ease  automated_readability_index  \\\n",
       "0                 13.0              -402.53                        244.8   \n",
       "1                  4.6              -234.72                        164.3   \n",
       "2                  6.0              -469.86                        274.6   \n",
       "3                  4.8              -369.72                        223.1   \n",
       "4                  2.5              -297.65                        186.9   \n",
       "...                ...                  ...                          ...   \n",
       "30278             26.0              -705.68                        396.5   \n",
       "30279             39.0              -419.45                        255.1   \n",
       "30280             52.0              -676.58                        379.6   \n",
       "30281             39.0              -452.94                        272.3   \n",
       "30282             28.0              -369.04                        227.6   \n",
       "\n",
       "       difficult_words  text_standard  reading_time  syllable_count  \n",
       "0                   62          192.0         31.05             627  \n",
       "1                   24            0.0         19.04             401  \n",
       "2                   66            0.0         36.14             767  \n",
       "3                   80           13.0         31.91             681  \n",
       "4                   58            0.0         25.93             560  \n",
       "...                ...            ...           ...             ...  \n",
       "30278               48            0.0         45.91             986  \n",
       "30279               27            0.0         29.00             607  \n",
       "30280               84          297.0         47.58            1001  \n",
       "30281               47            0.0         32.16             686  \n",
       "30282               47          179.0         27.88             613  \n",
       "\n",
       "[30283 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pd.read_csv(\"Datasets/final_data.csv\")\n",
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a word level analysis using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data[\"tokenized_text\"] = final_data[\"cleaned_essay_text\"].apply(word_tokenize)\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec(final_data[\"tokenized_text\"], vector_size=1500, window=5, min_count=1, workers=4)\n",
    "\n",
    "vect = np.array([get_avg_w2v_vector(essay, w2v_model) for essay in final_data[\"tokenized_text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_features = np.array(final_data.drop(columns=['score', 'cleaned_essay_text', 'tokenized_text']))\n",
    "X = np.hstack((vect, additional_features))\n",
    "y = final_data[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word2vec.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(w2v_model, 'word2vec.pkl', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antrskarya/VScode/.venv/lib/python3.12/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/antrskarya/VScode/.venv/lib/python3.12/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/antrskarya/VScode/.venv/lib/python3.12/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/antrskarya/VScode/.venv/lib/python3.12/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/antrskarya/VScode/.venv/lib/python3.12/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "# Assuming 5 folds and a random seed of 42 for reproducibility\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "models_lgbm = []\n",
    "\n",
    "# Define parameters\n",
    "params = {  \n",
    "        'metrics': 'None',\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 5,\n",
    "        'num_leaves': 10, # should be a number smaller than \"max_depth\"^2\n",
    "        'colsample_bytree': 0.3,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'reg_alpha': 0.7,\n",
    "        'reg_lambda' : 0.1,\n",
    "        'n_estimators': 700,\n",
    "        'extra_trees' : True,\n",
    "        'verbosity': -100}\n",
    "\n",
    "for train_idx, val_idx in folds.split(X_train, y_train):\n",
    "    # Create LightGBM datasets for training and validation folds\n",
    "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "    train_data_fold = lgb.Dataset(X_train_fold, label=y_train_fold.values)\n",
    "    val_data_fold = lgb.Dataset(X_val_fold, label=y_val_fold.values, reference=train_data_fold)\n",
    "    model1 = lgb.train(params, train_data_fold, valid_sets=[train_data_fold, val_data_fold])\n",
    "    models_lgbm.append(model1)\n",
    "\n",
    "    # Train the model on the current fold's training data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_lgbm = []\n",
    "for model in models_lgbm:\n",
    "    # Predict the probabilities for the test features using the selected features\n",
    "    proba_lgbm = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    probabilities_lgbm.append(proba_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lgbm = np.mean(probabilities_lgbm, axis=0)\n",
    "predictions_lgbm_clip = np.round(predictions_lgbm.clip(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8068087350411762"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwk2 = cohen_kappa_score(y_test, predictions_lgbm_clip, weights='quadratic')\n",
    "qwk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models_lgbm.pkl', 'wb') as f:\n",
    "    pickle.dump(models_lgbm, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_xgb = []\n",
    "\n",
    "\n",
    "for train_idx, val_idx in folds.split(X_train, y_train):\n",
    "    # Create LightGBM datasets for training and validation folds\n",
    "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "    model2 = xgb.XGBRegressor(objective = 'reg:squarederror',\n",
    "                eval_metric = 'rmse',\n",
    "                learning_rate = 0.05,\n",
    "                max_depth = 5,\n",
    "                subsample = 0.8,\n",
    "                min_child_weight = 5,\n",
    "                n_estimators=1000,\n",
    "                random_state=42,\n",
    "                verbosity=0)\n",
    "    model2.fit(X_train_fold, y_train_fold)\n",
    "    models_xgb.append(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_xgb = []\n",
    "for model in models_xgb:\n",
    "    # Predict the probabilities for the test features using the selected features\n",
    "    proba_xgb = model.predict(X_test)\n",
    "    probabilities_xgb.append(proba_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_xgb = np.mean(probabilities_xgb, axis=0)\n",
    "predictions_xgb_clip = np.round(predictions_xgb.clip(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8036241351152345"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwk2 = cohen_kappa_score(y_test, predictions_xgb_clip, weights='quadratic')\n",
    "qwk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models_xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(models_xgb, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_final = np.array((predictions_lgbm, predictions_xgb))\n",
    "prediction_final = np.mean(prediction_final, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_final_clip = np.round(prediction_final.clip(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8047519022416539"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwk2 = cohen_kappa_score(y_test, prediction_final_clip, weights='quadratic')\n",
    "qwk2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
